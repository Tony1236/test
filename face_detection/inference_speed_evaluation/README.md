## Inference Speed Evaluation

### Update History
* `2019.07.25` inference python code for MXNet-cudnn and TensorRT-cudnn is online.

### Additional Prerequirements
* [onnx](https://onnx.ai/) (pip3 install onnx==1.3.0)
* [pycuda](https://developer.nvidia.com/pycuda) (pip3 install pycuda==2019.1.1 or [install guide](https://pypi.org/project/pycuda/))
* [tensorrt](https://developer.nvidia.com/tensorrt) =5.x (use pip3 to install the corresponding .whl file in python folder)

> CAUTION:
>
> Carefully check the version compatible between CUDA, CUDNN, pycuda, TensorRT and onnx.


### Getting Started
Just modify and run the corresponding python script as your need.